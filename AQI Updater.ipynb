{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da62311-6810-49c1-878b-35084d42aaea",
   "metadata": {},
   "source": [
    "> Part of a series on auto-updating websites using GitHub Actions and GitHub Pages\n",
    "\n",
    "# Air Quality Updater: Complete dataset copier\n",
    "\n",
    "In this section, we are going to download the [AQI data of major cities from IQAir](https://www.iqair.com/us/world-air-quality-ranking) and save it as a CSV file.\n",
    "\n",
    "The URL is 'https://www.iqair.com/us/thailand/chiang-mai'.\n",
    "\n",
    "This approach is useful if you are looking to **directly copy a full dataset from the web** and use it to update a page or graphic. The alternate would be saving historical data over time, which I'll cover in another video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392ba48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from io import StringIO\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca9e47a-301d-4295-8027-0c48fd654de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date: 2024-05-31\n"
     ]
    }
   ],
   "source": [
    "# Get the current date\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "print(f\"Current Date: {current_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ad3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch AQI data from the website\n",
    "url = 'https://www.iqair.com/us/thailand/chiang-mai'\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check for request errors\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching data: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89094df8-9704-4d2d-b73b-e213565f1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27669dfd-85a9-4d4f-bac0-c8d51534404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tables using StringIO to avoid the FutureWarning\n",
    "tables = pd.read_html(StringIO(str(soup)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e50bc7-6d98-4fb0-b341-a309a74d34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the desired table is in the response\n",
    "if len(tables) > 3:\n",
    "    df = tables[3]  # Assuming the required table is at index 3\n",
    "else:\n",
    "    print(\"Error: Expected table not found.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed7ccb6-aad0-4b4b-94a1-1dc7a5c910e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the current date to the dataframe\n",
    "df['date_pulled'] = current_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f69d9f-1921-4158-9301-2da0afcdc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the AQI column to retain only the number\n",
    "if 'Air quality index' in df.columns:\n",
    "    df['Air quality index'] = df['Air quality index'].str.extract(r'(\\d+)').astype(int)  # Use raw string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c778a795-c9e7-4dc2-93a1-1750f9c023b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns to make 'date_pulled' the first column\n",
    "first_column = df.pop('date_pulled')\n",
    "df.insert(0, 'date_pulled', first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d2379a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the CSV file\n",
    "file_path = 'aqi_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b41872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Read the existing data from the file\n",
    "    existing_df = pd.read_csv(file_path)\n",
    "    # Append the new data to the existing data\n",
    "    updated_df = pd.concat([existing_df, df])\n",
    "else:\n",
    "    # If the file does not exist, use the new data as the initial dataframe\n",
    "    updated_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6ade83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataframe to the CSV file\n",
    "updated_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3bbc560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date_pulled Air pollution level  Air quality index Main pollutant\n",
      "0  2024-05-30            Moderate                 98          PM2.5\n",
      "1  2024-05-30            Moderate                 98          PM2.5\n",
      "2  2024-05-31            Moderate                 98          PM2.5\n",
      "0  2024-05-31            Moderate                 98          PM2.5\n"
     ]
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "print(updated_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
